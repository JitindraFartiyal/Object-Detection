{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JitindraFartiyal/Object-Detection/blob/object-detection-v1/Yolov1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzYgLQahHNYX",
        "colab_type": "text"
      },
      "source": [
        "Connecting to Google drive to upload dataset. This step is only required if you are using Google Colab and uploading dataset from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y6KmakpRJu0",
        "colab_type": "code",
        "outputId": "64986a92-52e2-4130-d913-d91f5bce22af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCivLdScKWHU",
        "colab_type": "text"
      },
      "source": [
        "Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxCUs78JHTc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.models.detection import transform, transform\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHecGo64HXlm",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to do categorical encoding manually\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyzx2ROpIMcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_class(label):\n",
        "    for i in range(len(label)):\n",
        "        if label.iloc[i,0] == 'Car':\n",
        "            label.iloc[i,0] = 1\n",
        "        elif label.iloc[i,0] == 'Van':\n",
        "            label.iloc[i,0] = 2\n",
        "        elif label.iloc[i, 0] == 'Truck':\n",
        "            label.iloc[i, 0] = 3\n",
        "        elif label.iloc[i,0] == 'Pedestrian':\n",
        "            label.iloc[i,0] = 4\n",
        "        elif label.iloc[i,0] == 'Person_sitting':\n",
        "            label.iloc[i,0] = 5\n",
        "        elif label.iloc[i,0] == 'Cyclist':\n",
        "            label.iloc[i,0] = 6\n",
        "        elif label.iloc[i,0] == 'Tram':\n",
        "            label.iloc[i,0] = 7\n",
        "        elif label.iloc[i,0] == 'Misc':\n",
        "            label.iloc[i,0] = 8\n",
        "        elif label.iloc[i,0] == 'DontCare':\n",
        "            label.iloc[i,0] = 9\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaCrcuTHIWGC",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to convert target class into a Yolo target class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onG5FIbgIeYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_target(target):\n",
        "    top_left_x = target[:, 1:2]\n",
        "    top_left_y = target[:, 2:3]\n",
        "    bottom_right_x = target[:, 3:4]\n",
        "    bottom_right_y = target[:, 4:5]\n",
        "\n",
        "    height = top_left_y-bottom_right_y\n",
        "    width = bottom_right_x-top_left_x\n",
        "    center_x = top_left_x + width/2\n",
        "    center_y = bottom_right_y + height/2\n",
        "\n",
        "    target[:, 1:2] = center_x/375\n",
        "    target[:, 2:3] = center_y/1242\n",
        "    target[:, 3:4] = height /1242\n",
        "    target[:, 4:5] = width/375\n",
        "\n",
        "    total_classes = torch.zeros(target.size()[0],target.size()[1]+4)\n",
        "    total_classes[:,:-4] = target\n",
        "\n",
        "    for i in range(0,len(target)):\n",
        "        if(total_classes[i,0:1] == 1):\n",
        "            total_classes[i,-4:-3] = 1\n",
        "        if(total_classes[i,0:1] == 2):\n",
        "            total_classes[i,-3:-2] = 1\n",
        "        if(total_classes[i,0:1] == 3):\n",
        "            total_classes[i,-2:-1] = 1\n",
        "        if(total_classes[i,0:1] == 4):\n",
        "            total_classes[i,-1] = 1\n",
        "    target = total_classes\n",
        "    return target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpTW24lZIr0w",
        "colab_type": "text"
      },
      "source": [
        "Defining custom training Dataset class | Kitti Dataset used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nlWbN5nIxZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KittiDataset(Dataset):\n",
        "\n",
        "    def __init__(self, labels_dir, images_dir, transform = None):\n",
        "        print('Initializing training dataset')\n",
        "        self.labels_dict = {}\n",
        "        self.labels_dir = labels_dir\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.filename = []\n",
        "\n",
        "        print('Labels Directory : ' + labels_dir)\n",
        "        print('Images Directory : ' + images_dir)\n",
        "\n",
        "        counter = 0\n",
        "        for file in os.listdir(self.labels_dir):\n",
        "            print('Reading label file -- : ' + file)\n",
        "            label_path = self.labels_dir + '/' + file\n",
        "            label = pd.read_csv(filepath_or_buffer=label_path, sep=' ', header=None, index_col=False)\n",
        "            label = label.iloc[:,[0,5,6,7,8,14]]\n",
        "\n",
        "            convert_class(label)\n",
        "            label.columns = ['Class','LeftTopX','LeftTopY','RightBottomX','RightBottomY','Score']\n",
        "            self.labels_dict[counter] = label\n",
        "            self.filename.append(file[0:6])\n",
        "            counter = counter + 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_dict)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.images_dir + '/' + self.filename[index] + '.png'\n",
        "        image = io.imread(image_path)\n",
        "\n",
        "        label = np.array(self.labels_dict[index])\n",
        "        image = skimage.transform.resize(image,(225,225),preserve_range=True)\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        image = torch.from_numpy(image).float()\n",
        "        label = torch.from_numpy(label).float()\n",
        "        label = transform_target(label)\n",
        "        label = label.view(-1)\n",
        "\n",
        "        sample = {'image' : image, 'label' : label}\n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJEfuQgRIJK",
        "colab_type": "text"
      },
      "source": [
        "Defining custom Testing Dataset. Used only for preliminary testing. Not mandatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGWyvCRkRKE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestKittiDataset(Dataset):\n",
        "\n",
        "    def __init__(self, labels_dir, images_dir, transform = None):\n",
        "        print('Initializing testing dataset')\n",
        "        self.labels_dir = labels_dir\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.filename = []\n",
        "\n",
        "        print('Test Labels Directory : ' + labels_dir)\n",
        "        print('Test Images Directory : ' + images_dir)\n",
        "\n",
        "        for file in os.listdir(self.labels_dir):\n",
        "            self.filename.append(file[0:6])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.filename)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.images_dir + '/' + self.filename[index] + '.png'\n",
        "        image = io.imread(image_path)\n",
        "        image = skimage.transform.resize(image,(225,225),preserve_range=True)\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        image = torch.from_numpy(image).float()\n",
        "        sample = {'image' : image}\n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOvQc2zSI5QT",
        "colab_type": "text"
      },
      "source": [
        "Defining Neural Network class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghm2SIYEI8TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        print('Initializing Convolutional Neural Network')\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=1, stride=1, padding=0,bias=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, stride=1, padding=0,bias=True)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, stride=1, padding=0,bias=True)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0,bias=True)\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=64,kernel_size=1, stride=1, padding=0,bias=True)\n",
        "        self.fc1 = nn.Linear(25*25*64,25*25*32,bias=True)\n",
        "        self.fc2 = nn.Linear(25*25*32,25*25*14,bias=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(input=x, kernel_size=3,stride=3)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.max_pool2d(input=x, kernel_size=3,stride=3)\n",
        "        x = x.view(-1,25*25*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHSSYHVuJDIK",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to calculate Intersection of Union (IOU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x-gK3JJJGq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_IOU(input_box,target_box):\n",
        "    anchor_box = torch.zeros(4)\n",
        "    bounding_box = torch.zeros(4)\n",
        "    iou = 0\n",
        "\n",
        "    anchor_box[0] = input_box[0] - (input_box[3])/2\n",
        "    anchor_box[1] = input_box[1] + (input_box[2]) / 2\n",
        "    anchor_box[2] = input_box[0] + (input_box[3]) / 2\n",
        "    anchor_box[3] = input_box[1] - (input_box[2]) / 2\n",
        "\n",
        "    bounding_box[0] = target_box[0] - (target_box[3]) / 2\n",
        "    bounding_box[1] = target_box[1] + (target_box[2]) / 2\n",
        "    bounding_box[2] = target_box[0] + (target_box[3]) / 2\n",
        "    bounding_box[3] = target_box[1] - (target_box[2]) / 2\n",
        "\n",
        "    if anchor_box[0]>bounding_box[0]:\n",
        "        xA = anchor_box[0]\n",
        "    else:\n",
        "        xA = bounding_box[0]\n",
        "\n",
        "    if anchor_box[1]>bounding_box[1]:\n",
        "        yA = anchor_box[1]\n",
        "    else:\n",
        "        yA = bounding_box[1]\n",
        "\n",
        "    if anchor_box[2]>bounding_box[2]:\n",
        "        xB = anchor_box[2]\n",
        "    else:\n",
        "        xB = bounding_box[2]\n",
        "\n",
        "    if anchor_box[3]>bounding_box[3]:\n",
        "        yB = anchor_box[3]\n",
        "    else:\n",
        "        yB = bounding_box[3]\n",
        "\n",
        "    if xB - xA + 1>0:\n",
        "        a = xB - xA + 1\n",
        "    if yB - yA + 1>0:\n",
        "        b = yB - yA + 1\n",
        "    intersection_area = a*b\n",
        "\n",
        "    anchor_box_area = (anchor_box[2] - anchor_box[0] + 1) * (anchor_box[3] - anchor_box[1] + 1)\n",
        "    bounding_box_area = (bounding_box[2] - bounding_box[0] + 1) * (bounding_box[3] - bounding_box[1] + 1)\n",
        "\n",
        "    iou = intersection_area / float(anchor_box_area + bounding_box_area - intersection_area)\n",
        "\n",
        "    return iou\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcCi1vneJLLa",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to convert Neural Network output into YOLO predicted output format\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRy3R09RJSn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_predict_output(output,threshold):\n",
        "    predicted_output = torch.zeros((25*25)+1, 9)\n",
        "    for grid_cell in range(0,(25*25)+1):\n",
        "        grid_output = output[grid_cell:grid_cell+14,:]\n",
        "\n",
        "        probability_class = grid_output[10:14,:]\n",
        "        \n",
        "        bounding_box1 = grid_output[0:5]\n",
        "        bounding_box1 = bounding_box1.view(-1,5)\n",
        "        bounding_box2 = grid_output[5:10]\n",
        "        bounding_box2 = bounding_box2.view(-1,5)\n",
        "\n",
        "        if(bounding_box1[0,0:1]>bounding_box2[0,0:1]):\n",
        "          temp_output = torch.zeros(bounding_box1.size()[0],bounding_box1.size()[1]+4)\n",
        "          temp_output[:,:-4] = bounding_box1\n",
        "          temp_output[:,5:9] = probability_class.view(-1,4)\n",
        "          predicted_output[grid_cell] = temp_output\n",
        "        elif(bounding_box1[0,0:1]<bounding_box2[0,0:1]):\n",
        "          temp_output = torch.zeros(bounding_box2.size()[0], bounding_box2.size()[1] + 4)\n",
        "          temp_output[:, :-4] = bounding_box2\n",
        "          temp_output[:,5:9] = probability_class.view(-1,4)\n",
        "          predicted_output[grid_cell] = temp_output\n",
        "    return predicted_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDZTDH6dJWlD",
        "colab_type": "text"
      },
      "source": [
        "Defining Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsmIgs8_JYsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_loss(output,target):\n",
        "    total_loss = 0\n",
        "    for grid_cell in range(0,(25*25)+1):\n",
        "      output_probability_class = output[grid_cell,5:9]\n",
        "      max_probability, indices = torch.max(output_probability_class,0)\n",
        "      \n",
        "      no_object_loss = 0\n",
        "      object_class_detected = False\n",
        "\n",
        "      if(output[grid_cell,0:1] > 0.5): \n",
        "        classification_loss = 10000\n",
        "        localization_loss = 10000\n",
        "        confidence_loss = 10000\n",
        "      \n",
        "        for i in range(0,target.size()[0]):\n",
        "          new_classification_loss = 0\n",
        "          new_localization_loss = 0\n",
        "          new_confidence_loss = 0\n",
        "          new_total_loss = 0\n",
        "        \n",
        "          if(indices.numpy() == target[i,0].numpy()):\n",
        "            object_class_detected = True      \n",
        "          \n",
        "            new_classification_loss = (output[grid_cell, -1]) ** 2 + (output[grid_cell, -2]) ** 2 + (output[grid_cell, -3]) ** 2 + (output[grid_cell, -4]) ** 2\n",
        "            new_classification_loss += 1 - (2 * output[grid_cell, (4 + indices)])\n",
        "                    \n",
        "            new_localization_loss = (output[grid_cell,1]-target[i,1])**2 + (output[grid_cell,2]-target[i,2])**2 \\\n",
        "                                 +(torch.sqrt(output[grid_cell,3])-torch.sqrt(target[i,3]))**2 \\\n",
        "                                 + (torch.sqrt(output[grid_cell,4])-torch.sqrt(target[i,4]))**2\n",
        "                    \n",
        "            new_confidence_loss = (calculate_IOU(output[grid_cell,1:5],target[i,1:5])*output[grid_cell,0:1])\n",
        "\n",
        "            new_total_loss = new_classification_loss + new_localization_loss + new_confidence_loss\n",
        "\n",
        "            if(new_total_loss < (classification_loss + localization_loss + confidence_loss)):\n",
        "              classification_loss = new_classification_loss\n",
        "              localization_loss = new_localization_loss\n",
        "              confidence_loss = new_confidence_loss\n",
        "\n",
        "        if(object_class_detected == False):\n",
        "          classification_loss = (output[grid_cell, -1]) ** 2 + (output[grid_cell, -2]) ** 2 + (output[grid_cell, -3]) ** 2 + (output[grid_cell, -4]) ** 2\n",
        "          localization_loss = (output[grid_cell,1]-target[i,1])**2 + (output[grid_cell,2]-target[i,2])**2 \\\n",
        "                                 +(torch.sqrt(output[grid_cell,3])-torch.sqrt(target[i,3]))**2 \\\n",
        "                                 + (torch.sqrt(output[grid_cell,4])-torch.sqrt(target[i,4]))**2\n",
        "          confidence_loss = (calculate_IOU(output[grid_cell,1:5],target[i,1:5])*output[grid_cell,0:1])\n",
        "\n",
        "        total_loss += classification_loss + localization_loss + confidence_loss\n",
        "      else:\n",
        "        no_object_loss += (output[grid_cell,0:1])**2\n",
        "        \n",
        "      total_loss += no_object_loss\n",
        "    return total_loss/625\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9vSE7fmJeRR",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbFltpQ6JgdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, epoch,threshold) :\n",
        "    print('Training the model with epoch : {}'.format(epoch))\n",
        "    model.train()\n",
        "    batch_loss = 0\n",
        "    for batch_index,data in enumerate(train_loader):\n",
        "        input = data['image']\n",
        "        target = data['label']\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(input)\n",
        "        output = torch.transpose(output,1,0)\n",
        "        predict_output = compute_predict_output(output, threshold)\n",
        "        loss = torch.FloatTensor(yolo_loss(predict_output,target))\n",
        "        batch_loss += loss\n",
        "        loss.requires_grad\n",
        "        \n",
        "        print('Loss for batch {} is : {}'.format(batch_index,loss))\n",
        "        # start debugger  \n",
        "        #import pdb; pdb.set_trace()        \n",
        "        loss.backward()\n",
        "        #for param in model.parameters():\n",
        "        #  print(param.grad.data.sum())\n",
        "        optimizer.step()\n",
        "        if(batch_index == 2):\n",
        "          break\n",
        "          \n",
        "    print('Loss:{} -- {} '.format(epoch, batch_loss/500))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxOqC1ERJ5xp",
        "colab_type": "text"
      },
      "source": [
        "Defining a function to test model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA1zdHgdJ8Fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader,threshold):\n",
        "  model.eval()\n",
        "  print('Testing the model')\n",
        "  with torch.no_grad():\n",
        "    for batch_index, data in enumerate(test_loader):\n",
        "      output = model(data['image'])\n",
        "      output = torch.transpose(output,1,0)\n",
        "      predicted_output = compute_predict_output(output,threshold)\n",
        "      center_x = predicted_output[0,1:2]*375\n",
        "      center_y = predicted_output[0,2:3]*1242\n",
        "      height = predicted_output[0,3:4]*1242\n",
        "      width = predicted_output[0,4:5]*375\n",
        "\n",
        "      top_left_x = center_x - (width/2)\n",
        "      top_left_y = center_y + (height/2)\n",
        "      bottom_right_x = center_x + (width/2)\n",
        "      bottom_right_y = center_y - (height/2)\n",
        "      data['image'] = data['image'][:3,:,:]\n",
        "      print('Image size : {}'.format(data['image'].size()))\n",
        "      image = data['image'].numpy()\n",
        "      image = np.reshape(225,225,3)\n",
        "      print('Image dim : {}'.format(image.ndim))\n",
        "      #skimage.transform.resize(image,(225,225,3))\n",
        "      image = cv2.rectangle(image,(top_left_x,top_left_y),(bottom_right_x,bottom_right_y),(255,0,0))\n",
        "      print(image)\n",
        "      save_path = r'/content/gdrive/My Drive/kitti_single_small/testing/results/image'+str(batch_index)+'.png'\n",
        "      cv2.imwrite(save_path,image)\n",
        "      plt.imshow(image)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU9gLfZyJox3",
        "colab_type": "text"
      },
      "source": [
        "Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nkCwlPQJqWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    print('Main starts')\n",
        "    # Training Settings\n",
        "    lr = 0.0001\n",
        "    momentum = 0.5\n",
        "    epochs = 1\n",
        "    batch_size = 1\n",
        "    threshold = 0.5\n",
        "    save_model = False\n",
        "\n",
        "    labels_dir = r'/content/gdrive/My Drive/kitti_single_small/training/label_2'\n",
        "    images_dir = r'/content/gdrive/My Drive/kitti_single_small/training/image_2'\n",
        "    test_images_dir = r'/content/gdrive/My Drive/kitti_single_small/testing/image_2'\n",
        "    saving_model_path = r'/content/gdrive/My Drive/kitti_single_small/yolo.cnn.pt'\n",
        "\n",
        "    if(save_model == False):\n",
        "      model = Net()\n",
        "      if(os.path.isfile(saving_model_path)):\n",
        "        model.load_state_dict(torch.load(saving_model_path))\n",
        "      save_model = True\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(),lr=lr, betas=(0.9,0.999))\n",
        "\n",
        "    training_dataset = KittiDataset(labels_dir=labels_dir,images_dir=images_dir, transform=None)\n",
        "    testing_dataset = TestKittiDataset(labels_dir=labels_dir,images_dir=test_images_dir, transform=None)\n",
        "\n",
        "    train_loader = DataLoader(dataset=training_dataset)\n",
        "    test_loader = DataLoader(dataset=testing_dataset)\n",
        "    \n",
        "    print('Training starts')\n",
        "    for epoch in range(1,2):\n",
        "        train(model, train_loader, optimizer,epoch,threshold)\n",
        "    \n",
        "    print('Testing starts')\n",
        "    test(model,test_loader,0.6)\n",
        "\n",
        "    if (save_model):\n",
        "        torch.save(model.state_dict(), saving_model_path)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}